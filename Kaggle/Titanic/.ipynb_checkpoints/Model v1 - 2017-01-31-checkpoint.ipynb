{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from scipy import stats\n",
    "\n",
    "for pd_option in ['display.max_rows', 'display.max_colwidth', 'display.max_columns']:\n",
    "    pd.set_option(pd_option, 500)  # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ggplot import *\n",
    "%matplotlib inline\n",
    "figsize(16, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, Normalizer, Imputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Models\n",
    "import statsmodels.api as sm \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier # SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV, chi2, f_classif, SelectFromModel, SelectPercentile, SelectKBest, VarianceThreshold\n",
    "\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "#features = [0, 1, (0, 1)]\n",
    "#fig, axs = plot_partial_dependence(clf, X, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split values based on the two CSVs\n",
    "training = pd.read_csv(\"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\")\n",
    "testing = pd.read_csv(\"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\")\n",
    "training.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert categorical values to integers\n",
    "train_mini = training.copy()\n",
    "train_mini.loc[train_mini['Embarked'] == 'C', 'Embarked'] = 1\n",
    "train_mini.loc[train_mini['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "train_mini.loc[train_mini['Embarked'] == 'S', 'Embarked'] = 3\n",
    "\n",
    "train_mini.loc[train_mini['Sex'] == 'male', 'Sex'] = 1\n",
    "train_mini.loc[train_mini['Sex'] == 'female', 'Sex'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_mini[['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare']]\n",
    "target = train_mini['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 5 columns):\n",
      "Pclass    891 non-null int64\n",
      "Sex       891 non-null object\n",
      "SibSp     891 non-null int64\n",
      "Parch     891 non-null int64\n",
      "Fare      891 non-null float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = train_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-04ff5750dffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         if (self.__class__.__name__ != 'MNLogit' and\n\u001b[1;32m    403\u001b[0m                 not np.all((self.endog >= 0) & (self.endog <= 1))):\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[1;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDiscreteModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_on_perfect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 60\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\model.pyc\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\data.pyc\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 566\u001b[0;31m                  **kwargs)\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\data.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[1;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Dan\\Anaconda2\\lib\\site-packages\\statsmodels\\base\\data.pyc\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n\u001b[0m\u001b[1;32m    429\u001b[0m                              \"Check input data with np.asarray(data).\")\n\u001b[1;32m    430\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(target, features)\n",
    "\n",
    "result = logit_model.fit(maxiter=50) \n",
    "print result.summary(), '\\n\\n'\n",
    "cm = result.pred_table()\n",
    "cm_df = pd.DataFrame(data=cm, columns=['churn_pred', 'renew_pred'], index=['churn', 'renew'])\n",
    "print cm_df, '\\n\\n', (cm[[0]][0][0] + cm[[1]][0][1] * 1.0) / sum(sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training count (596, 5), testing count (295, 5)\n",
      "Overall renewal rate from data 38, renewal rate in training 37, renewal rate in test 40\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)\n",
    "print \"Training count {0}, testing count {1}\".format(str(X_train.shape), str(X_test.shape))\n",
    "print \"Overall renewal rate from data {}, renewal rate in training {}, renewal rate in test {}\".format(\n",
    "    str(int(target.sum() * 1.0/target.shape[0]*100)), \n",
    "    str(int(y_train.sum()* 1.0/y_train.shape[0]*100)), \n",
    "    str(int(y_test.sum()* 1.0/y_test.shape[0]*100))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(model, feature_data, target_data):\n",
    "    X_train, X_test, features = feature_data\n",
    "    y_train, y_test, target = target_data\n",
    "    model.fit(X_train, y_train)\n",
    "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "    cm_df = pd.DataFrame(data=cm, columns=['churn_pred', 'renew_pred'], index=['churn', 'renew'])\n",
    "    print cm_df, '\\n', (cm[[0]][0][0] + cm[[1]][0][1] * 1.0) / sum(sum(cm))\n",
    "    scores = cross_val_score(model, features, target, cv=5)\n",
    "    print np.mean(scores), '\\n', scores\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "\n",
      "       churn_pred  renew_pred\n",
      "churn         170           5\n",
      "renew          62          58 \n",
      "0.772881355932\n",
      "0.781210389295 \n",
      "[ 0.74301676  0.79329609  0.78089888  0.7752809   0.81355932]\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "KNN Classifier\n",
      "       churn_pred  renew_pred\n",
      "churn         145          30\n",
      "renew          39          81 \n",
      "0.766101694915\n",
      "0.774512401114 \n",
      "[ 0.73743017  0.73184358  0.81460674  0.80337079  0.78531073]\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "MLP Classifier\n",
      "       churn_pred  renew_pred\n",
      "churn         136          39\n",
      "renew          21          99 \n",
      "0.796610169492\n",
      "0.757683647737 \n",
      "[ 0.66480447  0.7877095   0.76404494  0.78089888  0.79096045]\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "RandomForest Classifier\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "# logistic regression model\n",
    "print \"Logistic Regression Model\\n\"\n",
    "\n",
    "log_model = LogisticRegression(class_weight={0.0: 0.6, 1.0: 0.4}, C=1, fit_intercept=True)\n",
    "log_model = get_model(log_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "#######################################################################################################################\n",
    "print \"KNN Classifier\"\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7, weights='distance', p=2)\n",
    "knn_model = get_model(knn_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "#######################################################################################################################\n",
    "print \"MLP Classifier\"\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(1000, ), activation='logistic')\n",
    "mlp_model = get_model(mlp_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "print \"RandomForest Classifier\"\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight={0.0: 0.6, 1.0: 0.4},\n",
    "    max_features=None,\n",
    "    max_depth=None, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=10, \n",
    "    n_estimators=1000\n",
    ")\n",
    "rf_model = get_model(rf_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "print \"Naive Bayes\"\n",
    "naive_model = GaussianNB()\n",
    "naive_model = get_model(naive_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "print \"SVM Model\"\n",
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "svm_model = get_model(svm_model, [X_train, X_test, features], [y_train, y_test, target])\n",
    "\n",
    "print '\\n--------------------------------------------\\n'\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "print \"Voting Classifier\\n\"\n",
    "vote_model = VotingClassifier(\n",
    "    estimators=[('log', log_model), ('knn', knn_model)], \n",
    "    voting='soft', \n",
    "    weights=[1, 1]\n",
    ")\n",
    "\n",
    "vote_model = get_model(vote_model, [X_train, X_test, features], [y_train, y_test, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['has_expansion', 'has_companygoal', 'has_employeegoal', 'has_subgoal', 'has_scheduled_report',\n",
    "                       'has_champion', 'using_skilljar', 'has_core_features']\n",
    "anova_filter = SelectKBest(f_classif, k=10)\n",
    "\n",
    "\n",
    "feature_pipeline = Pipeline([\n",
    "    ('imputer', Imputer(strategy='median', axis=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('anova_filter', anova_filter)\n",
    "])\n",
    "\n",
    "features = feature_pipeline.fit_transform(X=train_features, y=target)\n",
    "\n",
    "cols = [retention_features.columns[idx] for idx in feature_pipeline.named_steps['anova_filter'].get_support(indices=True)]\n",
    "features = pd.DataFrame(features, columns=cols)\n",
    "\n",
    "# not certain that I need to do this but I think that it makes sense, encode \n",
    "for col in cols:\n",
    "    if col in categorical_columns:\n",
    "        min_val = features[col].min()\n",
    "        features[col] = features[col].apply(lambda x: 0 if x == min_val else 1)\n",
    "        \n",
    "print features.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
